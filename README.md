# Kaggle Dataset Analysis ðŸ“Š

> SQL &amp; Python analysis on Kaggle datasets.

[![star-useful](https://img.shields.io/badge/ðŸŒŸ-If%20useful-red.svg)](https://shields.io) 
[![view-repo](https://img.shields.io/badge/View-Repo-blueviolet)](https://github.com/iaks23?tab=repositories)
[![view-profile](https://img.shields.io/badge/Go%20To-Profile-orange)](https://github.com/iaks23) 

## Table of Contents

* [Big Query Public Dataset](#bigquery)
* [Pre-Requisites](#pre-requisite)
* [Getting Started](#started)
* [Projects](#projects)
* [Contribution](#contribution)

---------

# Big Query Public Dataset <a name='bigquery'></a>

[BigQuery](https://cloud.google.com/bigquery/docs/introduction) is a fully-managed enterprise data warehouse that helps you manage and analyze your data with built-in features like machine learning, geospatial analysis, and business intelligence. 

The public datasets are datasets that [BigQuery](https://cloud.google.com/bigquery/public-data) hosts for you to access and integrate into your applications. Google pays for the storage of these datasets and provides public access to the data via a project. 

Public datasets are available for you to analyze using either legacy SQL or standard SQL queries. 

> Use a fully qualified table name when querying public datasets,

```sql
bigquery-public-data.database-name.table-name.
```

Most of the datasets I've dealt with here are available as CSV files on [Kaggle](https://www.kaggle.com/datasets) as well. I've implemented this on mmy local with the help of Jupyter notebooks and respective libraries. 

# Pre-Requisites <a name='pre-requisite'></a>

To acess and perform analysis on my local system, I have used Jupyter notebooks and a few other Python libraries. 

[Here](https://www.youtube.com/watch?v=iNjXL9KbN4w&t=240s) is a wonderful tutorial I found on how to get started with Anaconda & Jupyter.

Ensuring that yoou have `pip` already installed, here are a few other libraries that you might also require. 

* google-api-python-client
* google-cloud-bigquery
* pyarrow (optional)
* pandas
* scikit-learn (optional)

ðŸ’¡ These libraries can be installed either directly in your notebook workspace / terminal mode inside the folder where pip is installed using the following command:

```python
pip install pandas
```

# Getting Started <a name='started'></a>

> ðŸš¨ Feel free to skip these steps if you are directly working on the dataset on Kaggle. 

The following steps will help you get started on setting up a Google Cloud API and service authentication, both which are required to call databases and tables in your local.

<details>
  
  <summary> Step 1: Creating A Service Account </summary>
  
  Access the [Google Service Account](https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts/create?supportedpurview=project&_ga=2.119421258.291474639.1638100719-2117592702.1638100719) page fromm your personal/professional ID.
  
  
 </details>
 
 <details>
  
  <summary> Step 2: Selecting an Existing Project/ Create a New Project </summary>
  
  If you're just getting started with the API client, you'll have to create a new project.
  
  ![img](https://github.com/iaks23/Kaggle_Dataset_Analysis/blob/main/img/1.png)
  
  In the `Service account name` field, enter a name. The Cloud Console fills in the `Service account ID` field based on this name.

  In the `Service account description field`, enter a description. For example, `Service account for quickstart`.
  
  Click Create and continue.
  
  Click the Select a `role` field.

  Under Quick access, click `Basic`, then click `Owner`.
  
  ![img](https://github.com/iaks23/Kaggle_Dataset_Analysis/blob/main/img/2.png)
  
  You're done creating a service account for the project!
  
 
 </details>
 
 <details>
  
  <summary> Step 3: Generate A Secret Client Key </summary>
  
  > In the Cloud Console, click the `email address` for the service account that you created.
    
  ![img](https://github.com/iaks23/Kaggle_Dataset_Analysis/blob/main/img/3.png)
  
  Go to the `keys` tab.
  
  ![img](https://github.com/iaks23/Kaggle_Dataset_Analysis/blob/main/img/3.1.png)
  
  Click `Add key`, then click `Create new key`.
 
  Click `Create`. A `JSON` key file is downloaded to your computer.
  
  
  ![img](https://github.com/iaks23/Kaggle_Dataset_Analysis/blob/main/img/3.2.png)
 
  </details>
  
  <details>
  
  <summary> Step 4: Setting the environment variable </summary>
  
  Before you begin importing the dataset onto your project, ensure the JSON file is in the same folder as the notebook. 
  
  You can then set up the authentication and environment variable setting with tbe following command 
  
  ```python
  
  import os
  os.environ["GOOGLE_APPLICATION_CREDENTIALS"]="/pathtoJSONFile"
  
  ```
  
  ### You're all done! âœ¨
 </details>
 

# Projects <a name='projects'></a>

|SNo|Project Name|Status|
|---|---|---|
|1|[Chicago Taxi Trips](https://github.com/iaks23/Kaggle_Dataset_Analysis/tree/main/Chicago_Taxi_Trips)|On-Going|



# Contribution <a name='contribution'></a>

Have you got an awesome project from an existing Kaggle dataset or wish to add onto mine? 

> To clone this repo into your local system, use the following command on a Command Prompt/Terminal or [Github Desktop](https://desktop.github.com)

```git
git clone https://github.com/iaks23/Kaggle_Dataset_Analysis.git
```

Make sure to leave a ðŸŒŸ if you found this useful!


-----
Â© Akshaya Parthasarathy, 2021 

Feedback is always welcome, drop a message on

[![LINKEDIN](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/akshaya-parthasarathy23)
[![INSTAGRAM](https://img.shields.io/badge/Instagram-E4405F?style=for-the-badge&logo=instagram&logoColor=white)](https://www.instagram.com/aks_sarathy/)
[![REDDIT](https://img.shields.io/badge/Reddit-FF4500?style=for-the-badge&logo=reddit&logoColor=white)](https://www.reddit.com/user/longstoryshort_)
